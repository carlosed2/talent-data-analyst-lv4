{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ST IT Cloud - Data and Analytics Test LV.4\n",
    "\n",
    "Esse teste deve avaliar alguns conceitos de big data e a qualidade técnica na manipulacão de dados, otimização de performance, trabalho com arquivos grandes e tratamento de qualidade.\n",
    "\n",
    "## Passo a passo\n",
    "\n",
    "- *Parte teórica:* responda as questões abaixo preenchendo as células em branco.\n",
    "- *Parte prática:* disponibilizamos aqui 2 cases para, leia os enunciados dos problemas, desenvolver os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
    "\n",
    "\n",
    "\n",
    "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
    "\n",
    "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
    "\n",
    "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 1** - Descreva de forma detalhada quais são as etapas na construção de um pipeline de dados, sem considerar ferramentas específicas, imagine que é seu primeiro contato com o cliente e você precisa entender a demanda dele e explicar quais são os passos que você terá que implementar para entregar a demanda."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cliente XPTO para entregarmos as informações com perfomance e com qualidade precisamos construir um pipeline de dados que constitui em:\r\n",
    "1: Levantamento e extração das origens dos seus dados, quais são os softwares, planilhas e sensores que geram os dados\r\n",
    "2: Transformar e limpar os dados obtidos, os dados não vem pronto para serem transformados em informações. Imagine que no software ou planilha tenhamos um campo aberto para digitar cpf, algumas pessoas digitam usando separadores outras não, nome com acentos outros não, até mesmo campos que deveriam ser preenchidos mas se encontram vazios.\r\n",
    "3: Parte final precisamos armazenar de acordo com a arquiquetura definida, para facilitar ja entregamos em tabelas, prontas para serem consultadas e gerar informação para seu negócio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 2** - Defina com suas palavras um processamento em streaming e processamento em batch. Qual sua experiência com cada uma delas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch: Processamento em lote, dados de um dia inteiro de vendas por exemplo, carregados em um determinado intervalo, de hora em hora, diario, semanal, mensal...\r\n",
    "Atualmente meus pipelines são unicamentes em batch, não tive demanda ainda com streaming. Apenas no curso que fiz pela coursera do GCP. \r\n",
    "Streaming: Dados processados em tempo real ou proximo do tempo real, geralmente dados de sensores ou transações bancarias."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 3** - Quais são as camadas de um Data Lake?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bronze - Dados brutos\r\n",
    "Prata - Dados pré processados\r\n",
    "Ouro - Dados prontos para serem consumidos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 4** - Quais as diferenças de um Data Lake e um DW?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data lake é o repositório de dados da empresa, onde podem ser armazenados qualquer tipo de dados, fotos, arquivos json, planilhas, parquet etc.\r\n",
    "DW é quando os dados ja estão processados, prontos gerarem valor ao negocio de forma rapida e pratica."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 5** - O que é arquitetura Lambda e Kappa? Descreva com suas palavras."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arquitetura lambda, possui duas camadas para processar os dados obtidos de origens, camada batch e streaming\r\n",
    "Arquitetura kappa trata todos os dados como eventos imutaveis e processados em uma camada unica"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 6** - O que é Data Quality para você e como você implementa isso nos seus processos?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para mim, data quality é garantir fidelidade e integridade das informações. Atualmente uso muito um step dentro da ferramenta de ETL pentaho que valida o schemas e alguns parametros definidos para as colunas do meu pipeline.\r\n",
    "Quando necessário, tambem utilizo a biblioteca pandera no python para realizar a mesma validação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 7** - Em uma escala de 0 a 10, qual seria seu nível de experiência com PySpark?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Escala 7, no banco hoje utilizamos poucas vezes. Dedico meu tempo vago para estudar PySpark na academia de ensino da Data Bricks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 8** - Em uma escala de 0 a 10, qual seria seu nível de experiência com SQL?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Escala 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 9** - Descreva suas expeciências com banco de dados SQL e NoSQL."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em SQL são anos de experiencia com consultas, CTE, procedures, views e tambem me arrisco em tunnings.\r\n",
    "Em NoSQL utlizei apenas um projeto no banco após realizar um curso na Dany Academy, basicamente apenas utilizando find para consultar dados do cliente e do recebedor do pagamento do boleto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 10** - Tem experiência com versionamento de código? Com quais ferramentas já trabalhou? Descreva."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apenas github e AzureDevOps. Mantendo meus ETL em python ou pentaho."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 11** - Tem experiência em desenvolvimento em cloud? Se sim, especifique a(s) plataforma(s) que já trabalhou e suas principais implementações e conhecimentos em cada serviço."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apenas cursos. GCP pela coursera e AWS seguindo arquitetura por eles e curso apartado udemy.\r\n",
    "Nos cursos GCP aprendi, BigQuery, cloud sql, cloud storage, cloud spanner, PubSub, CloudFirestore, DataStudio.\r\n",
    "Em AWS aprendi sobre os serviços Glue, Athena, S3, RedShift, EMR e Kinesis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 12** - Tem experiência com metodologia ágil? Qual?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "desde que entrei no banco modal utilizamos SCRUM e utilizo OKRs em algumas coisas pessoais e profissionais."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TESTE PRÁTICO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problema 1**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\r\n",
    "\r\n",
    "Após a normalização, gere reports que respondam as seguintes perguntas:\r\n",
    "- Quantos clientes temos nessa base?\r\n",
    "- Qual a média de idade dos clientes?\r\n",
    "- Quantos clientes nessa base pertencem a cada estado?\r\n",
    "- Quantos CPFs válidos e inválidos foram encontrados?\r\n",
    "- Quantos CNPJs válidos e inválidos foram encontrados?\r\n",
    "\r\n",
    "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas.\r\n",
    "\r\n",
    "*EXTRA:* executar as mesmas validações no *1E8.csv.gz"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instalar a biblioteca validate-docbr se não tiver instlada: pip install validate-docbr\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import validate_docbr as docbr\r\n",
    "from validate_docbr import CPF\r\n",
    "from validate_docbr import CNPJ\r\n",
    "\r\n",
    "cpf = CPF()\r\n",
    "cnpj = CNPJ()\r\n",
    "df = pd.read_csv('dados_cadastrais_fake.csv', sep=';')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removendo caracteres especiais das colunas cpf e cnpj \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "\r\n",
    "df.replace(to_replace=r'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ: ]', value='', regex=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalizando dados da coluna estado\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "df.replace(['sao  paulo', 'são  paulo'], 'SP',   inplace=True)\r\n",
    "df.replace(['rio de  janeiro '], 'RJ',   inplace=True)\r\n",
    "df.replace(['MINAS GERAI', 'MINAS GERAIs'], 'MG',   inplace=True)\r\n",
    "df.replace(['distrito federal'], 'DF',   inplace=True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "df['estado'].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG',\n",
       "       'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR',\n",
       "       'RS', 'SC', 'SE', 'SP', 'TO'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "df['cpf_valido'] = df['cpf'].apply(cpf.validate)\r\n",
    "df['cnpj_valido'] = df['cnpj'].apply(cnpj.validate)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantos clientes temos nessa base?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "df['nomes'].count()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Qual a média de idade dos clientes?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "df['idade'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "53.7831"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantos clientes nessa base pertencem a cada estado?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "df.groupby('estado')['nomes'].nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "estado\n",
       "AC    365\n",
       "AL    362\n",
       "AM    360\n",
       "AP    365\n",
       "BA    364\n",
       "CE    364\n",
       "DF    361\n",
       "ES    359\n",
       "GO    365\n",
       "MA    364\n",
       "MG    360\n",
       "MS    361\n",
       "MT    365\n",
       "PA    361\n",
       "PB    366\n",
       "PE    362\n",
       "PI    363\n",
       "PR    362\n",
       "RJ    362\n",
       "RN    359\n",
       "RO    363\n",
       "RR    362\n",
       "RS    360\n",
       "SC    361\n",
       "SE    363\n",
       "SP    363\n",
       "TO    363\n",
       "Name: nomes, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Todos Cpfs e Cnpj são válidos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "df[df[\"cpf_valido\"] == False].count()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nomes          0\n",
       "idade          0\n",
       "cidade         0\n",
       "estado         0\n",
       "cpf            0\n",
       "cnpj           0\n",
       "cpf_valido     0\n",
       "cnpj_valido    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "df[df[\"cnpj_valido\"] == False].count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nomes          0\n",
       "idade          0\n",
       "cidade         0\n",
       "estado         0\n",
       "cpf            0\n",
       "cnpj           0\n",
       "cpf_valido     0\n",
       "cnpj_valido    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando em csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "df.to_csv('problema1_normalizado.csv')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando em parquet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "df.to_parquet('df.parquet.gzip', compression='gzip')\r\n",
    "pd.read_parquet('df.parquet.gzip')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     nomes  idade           cidade estado          cpf  \\\n",
       "0           Dennis Daniels     31       ACRELÂNDIA     AC  97566536800   \n",
       "1              Leah Becker     42      ÁGUA BRANCA     AL  42526380707   \n",
       "2               Sally Ford     18         ALVARÃES     AM  34647754103   \n",
       "3           Colleen Duncan     21   SERRA DO NAVIO     AP  25253156003   \n",
       "4          Jeff Stephenson     73           ABAÍRA     BA  49668886542   \n",
       "...                    ...    ...              ...    ...          ...   \n",
       "9995  Rebekah Mitchell PhD     55          ABAIARA     CE  74482262234   \n",
       "9996       Lisa Parrish Jr     73         Brasília     DF  10683395190   \n",
       "9997      Michael Young MD     87   AFONSO CLÁUDIO     ES  53822363804   \n",
       "9998      Kevin Watson DDS     82  ABADIA DE GOIÁS     GO  11632512408   \n",
       "9999   Mr Joseph Wilson MD     50       AÇAILÂNDIA     MA  19213449208   \n",
       "\n",
       "                cnpj  cpf_valido  cnpj_valido  \n",
       "0     06589184909526        True         True  \n",
       "1     25673336235020        True         True  \n",
       "2     26543101702989        True         True  \n",
       "3     19062080510098        True         True  \n",
       "4     97794530015384        True         True  \n",
       "...              ...         ...          ...  \n",
       "9995  16740076932975        True         True  \n",
       "9996  32246978843482        True         True  \n",
       "9997  86601303758088        True         True  \n",
       "9998  08651414023648        True         True  \n",
       "9999  08908871516191        True         True  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomes</th>\n",
       "      <th>idade</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>cpf</th>\n",
       "      <th>cnpj</th>\n",
       "      <th>cpf_valido</th>\n",
       "      <th>cnpj_valido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dennis Daniels</td>\n",
       "      <td>31</td>\n",
       "      <td>ACRELÂNDIA</td>\n",
       "      <td>AC</td>\n",
       "      <td>97566536800</td>\n",
       "      <td>06589184909526</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leah Becker</td>\n",
       "      <td>42</td>\n",
       "      <td>ÁGUA BRANCA</td>\n",
       "      <td>AL</td>\n",
       "      <td>42526380707</td>\n",
       "      <td>25673336235020</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally Ford</td>\n",
       "      <td>18</td>\n",
       "      <td>ALVARÃES</td>\n",
       "      <td>AM</td>\n",
       "      <td>34647754103</td>\n",
       "      <td>26543101702989</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colleen Duncan</td>\n",
       "      <td>21</td>\n",
       "      <td>SERRA DO NAVIO</td>\n",
       "      <td>AP</td>\n",
       "      <td>25253156003</td>\n",
       "      <td>19062080510098</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Stephenson</td>\n",
       "      <td>73</td>\n",
       "      <td>ABAÍRA</td>\n",
       "      <td>BA</td>\n",
       "      <td>49668886542</td>\n",
       "      <td>97794530015384</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Rebekah Mitchell PhD</td>\n",
       "      <td>55</td>\n",
       "      <td>ABAIARA</td>\n",
       "      <td>CE</td>\n",
       "      <td>74482262234</td>\n",
       "      <td>16740076932975</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Lisa Parrish Jr</td>\n",
       "      <td>73</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>DF</td>\n",
       "      <td>10683395190</td>\n",
       "      <td>32246978843482</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Michael Young MD</td>\n",
       "      <td>87</td>\n",
       "      <td>AFONSO CLÁUDIO</td>\n",
       "      <td>ES</td>\n",
       "      <td>53822363804</td>\n",
       "      <td>86601303758088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Kevin Watson DDS</td>\n",
       "      <td>82</td>\n",
       "      <td>ABADIA DE GOIÁS</td>\n",
       "      <td>GO</td>\n",
       "      <td>11632512408</td>\n",
       "      <td>08651414023648</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Mr Joseph Wilson MD</td>\n",
       "      <td>50</td>\n",
       "      <td>AÇAILÂNDIA</td>\n",
       "      <td>MA</td>\n",
       "      <td>19213449208</td>\n",
       "      <td>08908871516191</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problema 2**: Você deverá implementar um programa, para ler, tratar e particionar os dados.\n",
    "\n",
    "O arquivo fonte está disponível em `https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz`\n",
    "\n",
    "### Data Quality\n",
    "\n",
    "- Higienizar e homogenizar o formato da coluna `document`\n",
    "- Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\n",
    "- Higienizar e homogenizar o formato da coluna `birthDate`\n",
    "- Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \n",
    "- Corrigir os dados com as colunas trocadas\n",
    "- Além desses pontos, existem outras tratamentos para homogenizar esse dataset. Aplique todos que conseguir.\n",
    "\n",
    "### Agregação dos dados\n",
    "\n",
    "- Quais são as 5 PF que mais gastaram (`totalSpent`)? \n",
    "- Qual é o valor de gasto médio por estado (`state`)?\n",
    "- Qual é o valor de gasto médio por `jobArea`?\n",
    "- Qual é a PF que gastou menos (`totalSpent`)?\n",
    "- Quantos nomes e documentos repetidos existem nesse dataset?\n",
    "- Quantas linhas existem nesse dataset?\n",
    "\n",
    "### Particionamento de dados tratados com as regras descritas em `DATA QUALITY`\n",
    "\n",
    "- Particionar em arquivos PARQUET por estado (`state`)\n",
    "- Particionar em arquivos CSV por ano/mes/dia de nascimento (`birthDate`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "0b433fcc5ccab1226e61b876b2608b88c737533f8f55929f0a97b97c5dced97d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}