{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ST IT Cloud - Data and Analytics Test LV.4\n",
    "\n",
    "Esse teste deve avaliar alguns conceitos de big data e a qualidade técnica na manipulacão de dados, otimização de performance, trabalho com arquivos grandes e tratamento de qualidade.\n",
    "\n",
    "## Passo a passo\n",
    "\n",
    "- *Parte teórica:* responda as questões abaixo preenchendo as células em branco.\n",
    "- *Parte prática:* disponibilizamos aqui 2 cases para, leia os enunciados dos problemas, desenvolver os programas, utilizando a **stack definida durante o processo seletivo**, para entregar os dados de acordo com os requisitos descritos abaixo.\n",
    "\n",
    "\n",
    "\n",
    "**Faz parte dos critérios de avaliacão a pontualidade da entrega. Implemente até onde for possível dentro do prazo acordado.**\n",
    "\n",
    "**Os dados de pessoas foram gerados de forma aleatória, utilizando a biblioteca FakerJS, FakerJS-BR e Faker**\n",
    "\n",
    "LEMBRE-SE: A entrega deve conter TODOS os passos para o avaliador executar o programa (keep it simple).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 1** - Descreva de forma detalhada quais são as etapas na construção de um pipeline de dados, sem considerar ferramentas específicas, imagine que é seu primeiro contato com o cliente e você precisa entender a demanda dele e explicar quais são os passos que você terá que implementar para entregar a demanda."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cliente XPTO para entregarmos as informações com perfomance e com qualidade precisamos construir um pipeline de dados que constitui em:\r\n",
    "1: Levantamento e extração das origens dos seus dados, quais são os softwares, planilhas e sensores que geram os dados\r\n",
    "2: Transformar e limpar os dados obtidos, os dados não vem pronto para serem transformados em informações. Imagine que no software ou planilha tenhamos um campo aberto para digitar cpf, algumas pessoas digitam usando separadores outras não, nome com acentos outros não, até mesmo campos que deveriam ser preenchidos mas se encontram vazios.\r\n",
    "3: Parte final precisamos armazenar de acordo com a arquiquetura definida, para facilitar ja entregamos em tabelas, prontas para serem consultadas e gerar informação para seu negócio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 2** - Defina com suas palavras um processamento em streaming e processamento em batch. Qual sua experiência com cada uma delas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch: Processamento em lote, dados de um dia inteiro de vendas por exemplo, carregados em um determinado intervalo, de hora em hora, diario, semanal, mensal...\r\n",
    "Atualmente meus pipelines são unicamentes em batch, não tive demanda ainda com streaming. Apenas no curso que fiz pela coursera do GCP. \r\n",
    "Streaming: Dados processados em tempo real ou proximo do tempo real, geralmente dados de sensores ou transações bancarias."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 3** - Quais são as camadas de um Data Lake?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bronze - Dados brutos\r\n",
    "Prata - Dados pré processados\r\n",
    "Ouro - Dados prontos para serem consumidos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 4** - Quais as diferenças de um Data Lake e um DW?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data lake é o repositório de dados da empresa, onde podem ser armazenados qualquer tipo de dados, fotos, arquivos json, planilhas, parquet etc.\r\n",
    "### DW é quando os dados ja estão processados, prontos para gerarem valor ao negocio de forma rapida e pratica."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 5** - O que é arquitetura Lambda e Kappa? Descreva com suas palavras."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Arquitetura lambda, possui duas camadas para processar os dados obtidos de origens, camada batch e streaming\r\n",
    "Arquitetura kappa trata todos os dados como eventos imutaveis e processados em uma camada unica"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 6** - O que é Data Quality para você e como você implementa isso nos seus processos?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para mim, data quality é garantir fidelidade e integridade das informações. Atualmente uso muito um step dentro da ferramenta de ETL pentaho que valida o schemas e alguns parametros definidos para as colunas do meu pipeline.\r\n",
    "Quando necessário, tambem utilizo a biblioteca pandera no python para realizar a mesma validação."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 7** - Em uma escala de 0 a 10, qual seria seu nível de experiência com PySpark?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Escala 7, no banco hoje utilizamos poucas vezes. Dedico meu tempo vago para estudar PySpark na academia de ensino da Data Bricks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 8** - Em uma escala de 0 a 10, qual seria seu nível de experiência com SQL?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Escala 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 9** - Descreva suas expeciências com banco de dados SQL e NoSQL."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Em SQL são anos de experiencia com consultas, CTE, procedures, views e tambem me arrisco em tunnings.\r\n",
    "Em NoSQL utlizei apenas um projeto no banco após realizar um curso na Dany Academy, basicamente apenas utilizando find para consultar dados do cliente e do recebedor do pagamento do boleto."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 10** - Tem experiência com versionamento de código? Com quais ferramentas já trabalhou? Descreva."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apenas github e AzureDevOps. Mantendo meus ETL em python ou pentaho."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 11** - Tem experiência em desenvolvimento em cloud? Se sim, especifique a(s) plataforma(s) que já trabalhou e suas principais implementações e conhecimentos em cada serviço."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apenas cursos. GCP pela coursera e AWS seguindo arquitetura por eles e curso apartado udemy.\r\n",
    "Nos cursos GCP aprendi, BigQuery, cloud sql, cloud storage, cloud spanner, PubSub, CloudFirestore, DataStudio.\r\n",
    "Em AWS aprendi sobre os serviços Glue, Athena, S3, RedShift, EMR e Kinesis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Questão 12** - Tem experiência com metodologia ágil? Qual?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "desde que entrei no banco modal utilizamos SCRUM e utilizo OKRs em algumas coisas pessoais e profissionais."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TESTE PRÁTICO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problema 1**: Você está recebendo o arquivo 'dados_cadastrais_fake.csv' que contem dados cadastrais de clientes, mas para que análises ou relatórios sejam feitos é necessário limpar e normalizar os dados. Além disso, existe uma coluna com o número de cpf e outra com cnpj, você precisará padronizar deixando apenas dígitos em formato string (sem caracteres especiais), implementar uma forma de verificar se tais documentos são válidos sendo que a informação deve se adicionada ao dataframe em outras duas novas colunas.\r\n",
    "\r\n",
    "Após a normalização, gere reports que respondam as seguintes perguntas:\r\n",
    "- Quantos clientes temos nessa base?\r\n",
    "- Qual a média de idade dos clientes?\r\n",
    "- Quantos clientes nessa base pertencem a cada estado?\r\n",
    "- Quantos CPFs válidos e inválidos foram encontrados?\r\n",
    "- Quantos CNPJs válidos e inválidos foram encontrados?\r\n",
    "\r\n",
    "Ao final gere um arquivo no formato csv e um outro arquivo no formato parquet chamado (problema1_normalizado), eles serão destinados para pessoas distintas.\r\n",
    "\r\n",
    "*EXTRA:* executar as mesmas validações no *1E8.csv.gz"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instalar a biblioteca validate-docbr se não tiver instlada: pip install validate-docbr\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "source": [
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import validate_docbr as docbr\r\n",
    "from validate_docbr import CPF\r\n",
    "from validate_docbr import CNPJ\r\n",
    "\r\n",
    "cpf = CPF()\r\n",
    "cnpj = CNPJ()\r\n",
    "df = pd.read_csv('dados_cadastrais_fake.csv', sep=';')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Removendo caracteres especiais das colunas cpf e cnpj \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "source": [
    "\r\n",
    "df.replace(to_replace=r'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ: ]', value='', regex=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalizando dados da coluna estado\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "source": [
    "df.replace(['sao  paulo', 'são  paulo'], 'SP',   inplace=True)\r\n",
    "df.replace(['rio de  janeiro '], 'RJ',   inplace=True)\r\n",
    "df.replace(['MINAS GERAI', 'MINAS GERAIs'], 'MG',   inplace=True)\r\n",
    "df.replace(['distrito federal'], 'DF',   inplace=True)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "source": [
    "df['estado'].unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG',\n",
       "       'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR',\n",
       "       'RS', 'SC', 'SE', 'SP', 'TO'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 332
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "source": [
    "df['cpf_valido'] = df['cpf'].apply(cpf.validate)\r\n",
    "df['cnpj_valido'] = df['cnpj'].apply(cnpj.validate)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantos clientes temos nessa base?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "source": [
    "df['nomes'].count()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 334
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Qual a média de idade dos clientes?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "source": [
    "df['idade'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "53.7831"
      ]
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quantos clientes nessa base pertencem a cada estado?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "source": [
    "df.groupby('estado')['nomes'].nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "estado\n",
       "AC    365\n",
       "AL    362\n",
       "AM    360\n",
       "AP    365\n",
       "BA    364\n",
       "CE    364\n",
       "DF    361\n",
       "ES    359\n",
       "GO    365\n",
       "MA    364\n",
       "MG    360\n",
       "MS    361\n",
       "MT    365\n",
       "PA    361\n",
       "PB    366\n",
       "PE    362\n",
       "PI    363\n",
       "PR    362\n",
       "RJ    362\n",
       "RN    359\n",
       "RO    363\n",
       "RR    362\n",
       "RS    360\n",
       "SC    361\n",
       "SE    363\n",
       "SP    363\n",
       "TO    363\n",
       "Name: nomes, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Todos Cpfs e Cnpj são válidos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "df[df[\"cpf_valido\"] == False].count()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nomes          0\n",
       "idade          0\n",
       "cidade         0\n",
       "estado         0\n",
       "cpf            0\n",
       "cnpj           0\n",
       "cpf_valido     0\n",
       "cnpj_valido    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 337
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "source": [
    "df[df[\"cnpj_valido\"] == False].count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nomes          0\n",
       "idade          0\n",
       "cidade         0\n",
       "estado         0\n",
       "cpf            0\n",
       "cnpj           0\n",
       "cpf_valido     0\n",
       "cnpj_valido    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 338
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando em csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "source": [
    "df.to_csv('problema1_normalizado.csv', index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Salvando em parquet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "df.to_parquet('df.parquet.gzip', compression='gzip')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problema 2**: Você deverá implementar um programa, para ler, tratar e particionar os dados.\r\n",
    "\r\n",
    "O arquivo fonte está disponível em `https://st-it-cloud-public.s3.amazonaws.com/people-v2_1E6.csv.gz`\r\n",
    "\r\n",
    "### Data Quality\r\n",
    "\r\n",
    "- Higienizar e homogenizar o formato da coluna `document`\r\n",
    "- Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\r\n",
    "### FEITO NA LEITURA DO ARQUIVO - Higienizar e homogenizar o formato da coluna `birthDate`\r\n",
    "- Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \r\n",
    "- Corrigir os dados com as colunas trocadas\r\n",
    "- Além desses pontos, existem outras tratamentos para homogenizar esse dataset. Aplique todos que conseguir.\r\n",
    "\r\n",
    "### Agregação dos dados\r\n",
    "\r\n",
    "- Quais são as 5 PF que mais gastaram (`totalSpent`)? \r\n",
    "- Qual é o valor de gasto médio por estado (`state`)?\r\n",
    "- Qual é o valor de gasto médio por `jobArea`?\r\n",
    "- Qual é a PF que gastou menos (`totalSpent`)?\r\n",
    "- Quantos nomes e documentos repetidos existem nesse dataset?\r\n",
    "- Quantas linhas existem nesse dataset?\r\n",
    "\r\n",
    "### Particionamento de dados tratados com as regras descritas em `DATA QUALITY`\r\n",
    "\r\n",
    "- Particionar em arquivos PARQUET por estado (`state`)\r\n",
    "- Particionar em arquivos CSV por ano/mes/dia de nascimento (`birthDate`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "# coluna birthDate tratada e higienizada \r\n",
    "df = pd.read_csv('people-v2_1E6.csv', sep=';', parse_dates=['birthDate'], dayfirst=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Higienizar e homogenizar o formato da coluna `document`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "df.replace(to_replace=r'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ: ]', value='', regex=True, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Detectar através da coluna `document` se o registro é de uma Pessoa Física ou Pessoa Jurídica, adicionando uma coluna com essa informação\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "source": [
    "df['TipoPessoa'] = np.where(df['document'].str.len() == 14, 'PJ', 'PF')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Existem duas colunas nesse dataset que em alguns registros estão trocadas. Quais são essas colunas? \r\n",
    "### **jobArea, phoneNumber**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "df.replace(['SP'], 'São Paulo',   inplace=True)\r\n",
    "df.replace(['GO'], 'Goiás',   inplace=True)\r\n",
    "df.replace(['PA'], 'Pará',   inplace=True)\r\n",
    "df.replace(['RJ'], 'Rio de Janeiro',   inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Formula para homogenizar a coluna state"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "source": [
    "def arrumaestado(uf):\r\n",
    "\r\n",
    "    states = {\r\n",
    "        'AC': 'Acre',\r\n",
    "        'AL': 'Alagoas',\r\n",
    "        'AP': 'Amapá',\r\n",
    "        'AM': 'Amazonas',\r\n",
    "        'BA': 'Bahia',\r\n",
    "        'CE': 'Ceará',\r\n",
    "        'DF': 'Distrito Federal',\r\n",
    "        'ES': 'Espírito Santo',\r\n",
    "        'GO': 'Goiás',\r\n",
    "        'MA': 'Maranhão',\r\n",
    "        'MT': 'Mato Grosso',\r\n",
    "        'MS': 'Mato Grosso do Sul',\r\n",
    "        'MG': 'Minas Gerais',\r\n",
    "        'PA': 'Pará',\r\n",
    "        'PB': 'Paraíba',\r\n",
    "        'PR': 'Paraná',\r\n",
    "        'PE': 'Pernambuco',\r\n",
    "        'PI': 'Piauí',\r\n",
    "        'RJ': 'Rio de Janeiro',\r\n",
    "        'RN': 'Rio Grande do Norte',\r\n",
    "        'RS': 'Rio Grande do Sul',\r\n",
    "        'RO': 'Rondônia',\r\n",
    "        'RR': 'Roraima',\r\n",
    "        'SC': 'Santa Catarina',\r\n",
    "        'SP': 'São Paulo',\r\n",
    "        'SE': 'Sergipe',\r\n",
    "        'TO': 'Tocantins'\r\n",
    "        }\r\n",
    "    if uf in states:\r\n",
    "        return states[uf]\r\n",
    "    else:\r\n",
    "        return uf\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "source": [
    "df['state_correct'] = df['state'].apply(arrumaestado)\r\n",
    "df = df[['document', 'name', 'job', 'jobArea', 'jobType', 'phoneNumber', 'birthDate', 'city', 'state_correct', 'totalSpent', 'TipoPessoa']]\r\n",
    "df = df.rename(columns={'state_correct':'state'})\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Quais são as 5 PF que mais gastaram (`totalSpent`)? \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "source": [
    "df[df['TipoPessoa'] == 'PF'].nlargest(5,'totalSpent')\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           document               name                             job  \\\n",
       "464764  18741688813  Sra Rocio Martins  Especialista Mobilidade Sênior   \n",
       "968481  82190864755  Euvanderson Costa      Supervisor Branding Sênior   \n",
       "4807    58953147670      Valeria Souza         Gerente Paradigma Chefe   \n",
       "233482  17195012700        Regina Melo  Especialista Identidade Frente   \n",
       "280776  61454551445     Wandir Martins                             NaN   \n",
       "\n",
       "             jobArea        jobType     phoneNumber  birthDate  \\\n",
       "464764  Configuração     Supervisor     45 91435347 1985-06-06   \n",
       "968481      Branding  Desenvolvedor    34 631235050 1965-10-25   \n",
       "4807          Contas     Planejador     57 37245403 1970-02-09   \n",
       "233482    Mobilidade  Desenvolvedor   Implementação 1962-07-18   \n",
       "280776    Otimização   Orquestrador  55 74 24317486 1988-09-11   \n",
       "\n",
       "                            city               state  totalSpent TipoPessoa  \n",
       "464764       Vania do Descoberto                Pará     1000.00         PF  \n",
       "968481              Grande Kacia          Pernambuco     1000.00         PF  \n",
       "4807       Ligeria do Descoberto             Alagoas      999.99         PF  \n",
       "233482            Martins do Sul  Mato Grosso do Sul      999.99         PF  \n",
       "280776  Martins de Nossa Senhora             Alagoas      999.99         PF  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "      <th>jobArea</th>\n",
       "      <th>jobType</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>totalSpent</th>\n",
       "      <th>TipoPessoa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464764</th>\n",
       "      <td>18741688813</td>\n",
       "      <td>Sra Rocio Martins</td>\n",
       "      <td>Especialista Mobilidade Sênior</td>\n",
       "      <td>Configuração</td>\n",
       "      <td>Supervisor</td>\n",
       "      <td>45 91435347</td>\n",
       "      <td>1985-06-06</td>\n",
       "      <td>Vania do Descoberto</td>\n",
       "      <td>Pará</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968481</th>\n",
       "      <td>82190864755</td>\n",
       "      <td>Euvanderson Costa</td>\n",
       "      <td>Supervisor Branding Sênior</td>\n",
       "      <td>Branding</td>\n",
       "      <td>Desenvolvedor</td>\n",
       "      <td>34 631235050</td>\n",
       "      <td>1965-10-25</td>\n",
       "      <td>Grande Kacia</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>58953147670</td>\n",
       "      <td>Valeria Souza</td>\n",
       "      <td>Gerente Paradigma Chefe</td>\n",
       "      <td>Contas</td>\n",
       "      <td>Planejador</td>\n",
       "      <td>57 37245403</td>\n",
       "      <td>1970-02-09</td>\n",
       "      <td>Ligeria do Descoberto</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>999.99</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233482</th>\n",
       "      <td>17195012700</td>\n",
       "      <td>Regina Melo</td>\n",
       "      <td>Especialista Identidade Frente</td>\n",
       "      <td>Mobilidade</td>\n",
       "      <td>Desenvolvedor</td>\n",
       "      <td>Implementação</td>\n",
       "      <td>1962-07-18</td>\n",
       "      <td>Martins do Sul</td>\n",
       "      <td>Mato Grosso do Sul</td>\n",
       "      <td>999.99</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280776</th>\n",
       "      <td>61454551445</td>\n",
       "      <td>Wandir Martins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Otimização</td>\n",
       "      <td>Orquestrador</td>\n",
       "      <td>55 74 24317486</td>\n",
       "      <td>1988-09-11</td>\n",
       "      <td>Martins de Nossa Senhora</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>999.99</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 347
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Qual é o valor de gasto médio por estado (`state`)?\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "source": [
    "df.groupby('state')['totalSpent'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "state\n",
       "Acre                   502.478424\n",
       "Alagoas                500.515519\n",
       "Amapá                  504.259137\n",
       "Amazonas               498.770663\n",
       "Bahia                  498.774140\n",
       "Ceará                  499.300300\n",
       "Distrito Federal       499.107366\n",
       "Espírito Santo         501.631747\n",
       "Goiás                  501.292493\n",
       "Maranhão               500.435299\n",
       "Mato Grosso            500.264610\n",
       "Mato Grosso do Sul     499.509741\n",
       "Minas Gerais           499.532094\n",
       "Paraná                 500.644200\n",
       "Paraíba                499.200399\n",
       "Pará                   499.230847\n",
       "Pernambuco             502.405773\n",
       "Piauí                  499.076521\n",
       "Rio Grande do Norte    499.756018\n",
       "Rio Grande do Sul      500.630983\n",
       "Rio de Janeiro         502.438569\n",
       "Rondônia               498.237318\n",
       "Roraima                500.956398\n",
       "Santa Catarina         501.345612\n",
       "Sergipe                498.240099\n",
       "São Paulo              498.694480\n",
       "Tocantins              501.901563\n",
       "Name: totalSpent, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 348
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "source": [
    "df.groupby('jobArea')['totalSpent'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "jobArea\n",
       "00 004351738    219.350000\n",
       "00 014307785    799.860000\n",
       "00 015257613    128.480000\n",
       "00 018374277    125.280000\n",
       "00 018700192    340.800000\n",
       "                   ...    \n",
       "Resposta        499.409451\n",
       "Segurança       503.234670\n",
       "Soluções        501.432619\n",
       "Táticas         498.413775\n",
       "Usabilidade     506.597001\n",
       "Name: totalSpent, Length: 50028, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 349
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Qual é a PF que gastou menos (`totalSpent`)?\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "source": [
    "df[df['TipoPessoa'] == 'PF'].nsmallest(1,'totalSpent')\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           document           name                           job  \\\n",
       "247394  58868926210  Sr Enio Souza  Consultor Marketing Distrito   \n",
       "\n",
       "             jobArea     jobType  phoneNumber  birthDate  \\\n",
       "247394  Comunicações  Assistente  06 24388107 1971-10-05   \n",
       "\n",
       "                              city  state  totalSpent TipoPessoa  \n",
       "247394  Vila Eloa de Nossa Senhora  Bahia         0.0         PF  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "      <th>jobArea</th>\n",
       "      <th>jobType</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>totalSpent</th>\n",
       "      <th>TipoPessoa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247394</th>\n",
       "      <td>58868926210</td>\n",
       "      <td>Sr Enio Souza</td>\n",
       "      <td>Consultor Marketing Distrito</td>\n",
       "      <td>Comunicações</td>\n",
       "      <td>Assistente</td>\n",
       "      <td>06 24388107</td>\n",
       "      <td>1971-10-05</td>\n",
       "      <td>Vila Eloa de Nossa Senhora</td>\n",
       "      <td>Bahia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 350
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Quantos nomes e documentos repetidos existem nesse dataset?\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "source": [
    "df.duplicated(subset=['name'], keep='first').sum()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "544986"
      ]
     },
     "metadata": {},
     "execution_count": 351
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "source": [
    "df.duplicated(subset=['document'], keep='first').sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Quantas linhas existem nesse dataset?\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000000, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 353
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# - Particionar em arquivos PARQUET por estado (`state`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "source": [
    "df.to_parquet('df_por_state.parquet.gzip', compression='gzip', partition_cols='state')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "0b433fcc5ccab1226e61b876b2608b88c737533f8f55929f0a97b97c5dced97d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}